{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0c3b26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\deepa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pinecone in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (8.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (2025.11.12)\n",
      "Requirement already satisfied: orjson>=3.0.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (3.11.4)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<4.0.0,>=3.0.1 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (3.0.1)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.1.0,>=0.0.7 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone) (2.5.0)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<4.0.0,>=3.0.1->pinecone) (3.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\deepa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.8.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\deepa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\deepa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\deepa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\deepa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install pinecone\n",
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ef71fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06155522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ec6b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_chatbot_response(client, model_name, messages, temperature=0, max_retries=3, retry_delay=2, try_without_model=False):\n",
    "    \"\"\"\n",
    "    Get chatbot response with error handling and retry logic.\n",
    "    Some RunPod endpoints have the model pre-configured and don't need the model parameter.\n",
    "    \n",
    "    Args:\n",
    "        client: OpenAI client instance\n",
    "        model_name: Name of the model to use (may be optional for some RunPod endpoints)\n",
    "        messages: List of message dictionaries\n",
    "        temperature: Temperature parameter (default: 0)\n",
    "        max_retries: Maximum number of retry attempts (default: 3)\n",
    "        retry_delay: Delay between retries in seconds (default: 2)\n",
    "        try_without_model: If True, try without model parameter if first attempt fails (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        str: Response content from the chatbot\n",
    "    \"\"\"\n",
    "    input_messages = []\n",
    "    for message in messages:\n",
    "        input_messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "    \n",
    "    # Validate inputs\n",
    "    if not input_messages:\n",
    "        raise ValueError(\"Messages list cannot be empty.\")\n",
    "    \n",
    "    # Retry logic for transient errors\n",
    "    last_exception = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Build request parameters\n",
    "            request_params = {\n",
    "                \"messages\": input_messages,\n",
    "                \"temperature\": temperature,\n",
    "                \"top_p\": 0.8,\n",
    "                \"max_tokens\": 2000,\n",
    "            }\n",
    "            \n",
    "            # Some RunPod endpoints have model pre-configured, so model parameter might not be needed\n",
    "            # Try with model first, then without if try_without_model is True\n",
    "            if model_name and (attempt == 0 or not try_without_model):\n",
    "                request_params[\"model\"] = model_name\n",
    "            \n",
    "            response = client.chat.completions.create(**request_params)\n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            last_exception = e\n",
    "            error_type = type(e).__name__\n",
    "            error_msg = str(e)\n",
    "            \n",
    "            # Check if it's a retryable error (500, 502, 503, 504)\n",
    "            is_retryable = (\n",
    "                \"500\" in error_msg or \n",
    "                \"502\" in error_msg or \n",
    "                \"503\" in error_msg or \n",
    "                \"504\" in error_msg or\n",
    "                \"InternalServerError\" in error_type\n",
    "            )\n",
    "            \n",
    "            # If first attempt failed with 500 and we haven't tried without model, try that\n",
    "            if (attempt == 0 and is_retryable and model_name and try_without_model):\n",
    "                print(f\"\\n‚ö†Ô∏è  First attempt failed. Trying without model parameter (model may be pre-configured in endpoint)...\")\n",
    "                continue\n",
    "            \n",
    "            if is_retryable and attempt < max_retries - 1:\n",
    "                print(f\"\\n‚ö†Ô∏è  Attempt {attempt + 1}/{max_retries} failed: {error_type}\")\n",
    "                print(f\"   Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                continue\n",
    "            else:\n",
    "                # Print detailed error information\n",
    "                print(f\"\\n‚ùå Error: {error_type}\")\n",
    "                print(f\"   Message: {error_msg}\")\n",
    "                \n",
    "                if \"500\" in error_msg or \"InternalServerError\" in error_type:\n",
    "                    print(f\"\\nüí° RunPod API Error (500) - Common causes:\")\n",
    "                    print(f\"   1. ‚ùå Invalid or expired RUNPOD_TOKEN\")\n",
    "                    print(f\"   2. ‚ùå Incorrect RUNPOD_CHATBOT_URL format\")\n",
    "                    print(f\"      Expected format: https://api.runpod.ai/v2/... or https://xxxxx-xxxxx.proxy.runpod.net/v1\")\n",
    "                    print(f\"   3. ‚ùå Model name '{model_name}' doesn't match deployed model\")\n",
    "                    print(f\"      Some RunPod endpoints have model pre-configured - try setting try_without_model=True\")\n",
    "                    print(f\"   4. ‚ùå RunPod service temporarily unavailable\")\n",
    "                    print(f\"   5. ‚ùå Request parameters incompatible with your RunPod endpoint\")\n",
    "                    print(f\"\\n   üìã Current Configuration:\")\n",
    "                    print(f\"      RUNPOD_TOKEN: {'‚úÖ Set' if os.getenv('RUNPOD_TOKEN') else '‚ùå NOT SET'}\")\n",
    "                    print(f\"      RUNPOD_CHATBOT_URL: {os.getenv('RUNPOD_CHATBOT_URL', '‚ùå NOT SET')}\")\n",
    "                    print(f\"      MODEL_NAME: {os.getenv('MODEL_NAME', '‚ùå NOT SET')}\")\n",
    "                    print(f\"\\n   üîß Troubleshooting:\")\n",
    "                    print(f\"      - Verify your RunPod endpoint is active in RunPod dashboard\")\n",
    "                    print(f\"      - Check if your endpoint URL includes '/v1' or '/v2'\")\n",
    "                    print(f\"      - Try calling with try_without_model=True if model is pre-configured\")\n",
    "                    print(f\"      - Ensure your RunPod token has access to the endpoint\")\n",
    "                elif \"401\" in error_msg or \"Unauthorized\" in error_msg:\n",
    "                    print(f\"\\nüí° Authentication Error: Check your RUNPOD_TOKEN\")\n",
    "                elif \"404\" in error_msg:\n",
    "                    print(f\"\\nüí° Not Found Error: Check your RUNPOD_CHATBOT_URL\")\n",
    "                elif \"429\" in error_msg:\n",
    "                    print(f\"\\nüí° Rate Limit Error: Too many requests. Please wait and try again.\")\n",
    "                else:\n",
    "                    print(f\"\\nüí° Check your API configuration and network connection.\")\n",
    "                \n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4081d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "            api_key=os.getenv(\"RUNPOD_TOKEN\"),\n",
    "            base_url=os.getenv(\"RUNPOD_CHATBOT_URL\"),\n",
    "        )\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d07455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ae661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "169aee36",
   "metadata": {},
   "source": [
    "# Get LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ba7753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  Attempt 1/3 failed: InternalServerError\n",
      "   Retrying in 2 seconds...\n",
      "\n",
      "‚ö†Ô∏è  Attempt 2/3 failed: InternalServerError\n",
      "   Retrying in 2 seconds...\n",
      "\n",
      "‚ùå Error: InternalServerError\n",
      "   Message: Error code: 500 - {'error': 'Error processing the request'}\n",
      "\n",
      "üí° RunPod API Error (500) - Common causes:\n",
      "   1. ‚ùå Invalid or expired RUNPOD_TOKEN\n",
      "   2. ‚ùå Incorrect RUNPOD_CHATBOT_URL format\n",
      "      Expected format: https://api.runpod.ai/v2/... or https://xxxxx-xxxxx.proxy.runpod.net/v1\n",
      "   3. ‚ùå Model name 'meta-llama/Meta-Llama-3-8B-Instruct' doesn't match deployed model\n",
      "      Some RunPod endpoints have model pre-configured - try setting try_without_model=True\n",
      "   4. ‚ùå RunPod service temporarily unavailable\n",
      "   5. ‚ùå Request parameters incompatible with your RunPod endpoint\n",
      "\n",
      "   üìã Current Configuration:\n",
      "      RUNPOD_TOKEN: ‚úÖ Set\n",
      "      RUNPOD_CHATBOT_URL: https://api.runpod.ai/v2/gkyzn0q9z4dlpx/openai/v1\n",
      "      MODEL_NAME: meta-llama/Meta-Llama-3-8B-Instruct\n",
      "\n",
      "   üîß Troubleshooting:\n",
      "      - Verify your RunPod endpoint is active in RunPod dashboard\n",
      "      - Check if your endpoint URL includes '/v1' or '/v2'\n",
      "      - Try calling with try_without_model=True if model is pre-configured\n",
      "      - Ensure your RunPod token has access to the endpoint\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'error': 'Error processing the request'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalServerError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m messages = [{\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mWhat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms the capital of Italy?\u001b[39m\u001b[33m\"\u001b[39m}]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43mget_chatbot_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mget_chatbot_response\u001b[39m\u001b[34m(client, model_name, messages, temperature, max_retries, retry_delay, try_without_model)\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mand\u001b[39;00m (attempt == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m try_without_model):\n\u001b[32m     43\u001b[39m         request_params[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model_name\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1189\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1187\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1188\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mInternalServerError\u001b[39m: Error code: 500 - {'error': 'Error processing the request'}"
     ]
    }
   ],
   "source": [
    "messages = [{'role':'user','content':\"What's the capital of Italy?\"}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac71a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d180eeb4",
   "metadata": {},
   "source": [
    "# Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1db3e",
   "metadata": {},
   "source": [
    "## Structred output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50ca843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\n",
      "    \"country\": \"Italy\",\n",
      "    \"capital\": \"Rome\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answer questions about capitals of countries.\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "[\n",
    "{\n",
    "    country: the country that you will get the capital of \n",
    "    capital: the capital of the country stated\n",
    "}\n",
    "]\n",
    "\"\"\"\n",
    "messages = [{'role':'system','content':system_prompt}]\n",
    "messages.append({'role':'user','content':\"What's the capital of Italy?\"})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71161a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b746b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4e9575d",
   "metadata": {},
   "source": [
    "## input structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "779e3f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"country\": \"Italy\",\n",
      "    \"capital\": \"Rome\"\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"France\",\n",
      "    \"capital\": \"Paris\"\n",
      "  },\n",
      "  {\n",
      "    \"country\": \"Germany\",\n",
      "    \"capital\": \"Berlin\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Get me the capitals of the following countries:\n",
    "```\n",
    "1. Italy\n",
    "2. France\n",
    "3. Germany\n",
    "``\n",
    "\"\"\"\n",
    "messages = [{'role':'system','content':system_prompt}]\n",
    "messages.append({'role':'user','content':user_prompt})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79c2718a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'},\n",
       " {'country': 'France', 'capital': 'Paris'},\n",
       " {'country': 'Germany', 'capital': 'Berlin'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21aefb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08ffda13",
   "metadata": {},
   "source": [
    "## Give the model time to think (Chain of thought)\n",
    "\n",
    "> https://arxiv.org/pdf/2205.11916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0019ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca28fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 1+3\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cce70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0bd98b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4113098.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "259/2*8654+91072*33-12971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91f7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 1431449.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6243f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2681649.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 1431449.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69998a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58c5128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    steps: This is where you solve the equation bit by bit following the BEDMAS order of operations. You need to show your work and calculate each step leading to final result. Feel free to write here in free text. \n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea4fb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"steps\": \"First, we need to follow the BEDMAS order of operations. \n",
      "    1. Divide 259 by 2: 259/2 = 129.5\n",
      "    2. Multiply 129.5 by 8654: 129.5 * 8654 = 1121011\n",
      "    3. Multiply 91072 by 33: 91072 * 33 = 3005016\n",
      "    4. Add 1121011 and 3005016: 1121011 + 3005016 = 4126027\n",
      "    5. Subtract 12971 from 4126027: 4126027 - 12971 = 4113056\",\n",
      "    \"result\": 4113056\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66cf1d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 4113056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aab814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e6b197",
   "metadata": {},
   "source": [
    "# RAG - Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1472c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b93c481",
   "metadata": {},
   "source": [
    "#### Asking about a subject that the LLM does not know anything about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05eefa05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since I'm not aware of any official information about the iPhone 16, I'll provide you with some general information about the latest iPhone models and some rumored features that might be included in future iPhone models.\n",
      "\n",
      "However, I can tell you about the latest iPhone models, such as the iPhone 14 series, which includes:\n",
      "\n",
      "1. iPhone 14\n",
      "2. iPhone 14 Plus\n",
      "3. iPhone 14 Pro\n",
      "4. iPhone 14 Pro Max\n",
      "\n",
      "Some of the key features of the iPhone 14 series include:\n",
      "\n",
      "1. Improved cameras with a new 48MP main camera on the Pro models\n",
      "2. Faster A16 Bionic chip\n",
      "3. Longer battery life\n",
      "4. New colors and designs\n",
      "5. Enhanced display with a higher refresh rate\n",
      "\n",
      "As for the iPhone 16, there's no official information available yet. However, based on rumors and leaks, here are some potential features that might be included:\n",
      "\n",
      "1. Improved cameras with a new periscope lens or a 3D modeling camera\n",
      "2. Faster A17 Bionic chip or a new chip design\n",
      "3. Enhanced display with a higher refresh rate or a new OLED panel\n",
      "4. New colors and designs\n",
      "5. Improved battery life and charging capabilities\n",
      "6. Enhanced biometric security with a new fingerprint sensor or facial recognition system\n",
      "7. Integration with augmented reality (AR) and virtual reality (VR) technologies\n",
      "8. Improved water and dust resistance\n",
      "9. Enhanced wireless charging capabilities\n",
      "10. New software features and updates to iOS\n",
      "\n",
      "Please note that these are just rumors and speculations, and Apple has not officially confirmed any of these features. I recommend checking Apple's official website or reputable tech news sources for the latest information on upcoming iPhone models.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f45f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e132c1",
   "metadata": {},
   "source": [
    "#### Giving Context to the unknown subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e753f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_16 = \"\"\"\n",
    "The iPhone 16 introduces several exciting updates, making it one of Apple's most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\n",
    "\n",
    "Powered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Apple‚Äôs \"Camera Control\" button for more flexible photography options.\n",
    "\n",
    "Apple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \n",
    "9TO5MAC\n",
    "\n",
    "APPLEMAGAZINE\n",
    ".\n",
    "\n",
    "Additionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31f5e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, the new features and updates in the iPhone 16 include:\n",
      "\n",
      "1. Larger display sizes:\n",
      "   - Base model: 6.1-inch\n",
      "   - iPhone 16 Plus: 6.7-inch\n",
      "   - iPhone 16 Pro: 6.3-inch\n",
      "   - iPhone 16 Pro Max: 6.9-inch\n",
      "\n",
      "2. Thinner bezels and a more durable Ceramic Shield.\n",
      "\n",
      "3. New A18 chip (A18 Pro for Pro models) for improved performance, with:\n",
      "   - Enhanced neural engine capabilities\n",
      "   - Faster GPU for gaming\n",
      "   - Machine learning tasks\n",
      "\n",
      "4. Upgraded camera systems:\n",
      "   - Base iPhone 16: Dual-camera setup with a 48MP main sensor\n",
      "   - Pro models: 48MP Ultra Wide and 5x telephoto camera, with Apple's \"Camera Control\" button\n",
      "\n",
      "5. Advanced audio features:\n",
      "   - \"Audio Mix\" for refined audio capture during video recording\n",
      "\n",
      "6. Extended battery life, especially in the iPhone 16 Pro Max.\n",
      "\n",
      "7. Switch to USB-C for faster charging and data transfer.\n",
      "\n",
      "8. Support for up to 2x faster video encoding in Pro models.\n",
      "\n",
      "9. Starting prices remain consistent with previous generations:\n",
      "   - iPhone 16: $799\n",
      "   - Pro models: $999\n"
     ]
    }
   ],
   "source": [
    "user_prompt = f\"\"\"\n",
    "{iphone_16}\n",
    "\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902232f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "546d94c8",
   "metadata": {},
   "source": [
    "#### Automatically extract context data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b0e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_s23 = \"\"\"\n",
    "The Samsung Galaxy S23 brings some incremental but notable upgrades to its predecessor, the Galaxy S22. It features the Snapdragon 8 Gen 2 processor, a powerful chip optimized for the S23 series, delivering enhanced performance, especially for gaming and multitasking. This chip ensures top-tier speed and efficiency across all models, from the base S23 to the larger S23+ and S23 Ultra‚Äã\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "In terms of design, the S23's camera module has been streamlined by removing the raised metal contour around the cameras, creating a cleaner, sleeker look. It also sports the same 6.1-inch 120Hz AMOLED display, protected by tougher Gorilla Glass Victus 2, making it more resistant to scratches and drops‚Äã\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "The S23 Ultra stands out with its 200MP main camera, offering impressive photo clarity, especially in low-light conditions. The selfie camera across the series has been updated to a 12MP sensor, resulting in sharper selfies. The Ultra model also includes productivity tools such as the S-Pen, which remains an essential feature for note-taking and creative tasks‚Äã\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "Battery life is solid, with the S23 Ultra featuring a 5000mAh battery that lasts comfortably through a day of heavy use. However, charging speeds still lag behind some competitors, with 45W wired charging, which is slower than other brands offering up to 125W charging‚Äã\n",
    "STUFF\n",
    ".\n",
    "\n",
    "Overall, the Galaxy S23 series enhances performance, durability, and camera quality, making it a strong contender for users seeking a high-performance flagship.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510711ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [iphone_16,samsung_s23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b9efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"What's new in iphone 16?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f90a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a12f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = OpenAI(\n",
    "        api_key=os.getenv(\"RUNPOD_TOKEN\"), \n",
    "        base_url=os.getenv(\"RUNPOD_EMBEDDING_URL\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b3fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(embedding_client,model_name,text_input):\n",
    "    output = embedding_client.embeddings.create(input = text_input,model=model_name)\n",
    "    \n",
    "    embedings = []\n",
    "    for embedding_object in output.data:\n",
    "        embedings.append(embedding_object.embedding)\n",
    "\n",
    "    return embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d06859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_embeddings = get_embedding(embedding_client,model_name,user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feb94816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.05110831558704376,\n",
       "  -0.03489653766155243,\n",
       "  0.06350376456975937,\n",
       "  -0.008884420618414879,\n",
       "  -0.03724740073084831,\n",
       "  -0.042040713131427765,\n",
       "  0.015921736136078835,\n",
       "  0.031126001849770546,\n",
       "  -0.01283814013004303,\n",
       "  0.04246814176440239,\n",
       "  0.05556579306721687,\n",
       "  0.01331899780780077,\n",
       "  -0.07211340963840485,\n",
       "  0.0014378030318766832,\n",
       "  0.09635474532842636,\n",
       "  0.028714081272482872,\n",
       "  0.11510057002305984,\n",
       "  -0.14752411842346191,\n",
       "  -0.07907439768314362,\n",
       "  0.016150716692209244,\n",
       "  -0.0367589071393013,\n",
       "  -0.014563122764229774,\n",
       "  -0.03975091129541397,\n",
       "  -0.030057430267333984,\n",
       "  0.030118491500616074,\n",
       "  0.06139714643359184,\n",
       "  0.0010905168019235134,\n",
       "  -0.012731282971799374,\n",
       "  -0.019188515841960907,\n",
       "  -0.1384870558977127,\n",
       "  -0.00042075058445334435,\n",
       "  -0.006739642005413771,\n",
       "  0.0166850034147501,\n",
       "  0.026943303644657135,\n",
       "  0.000493737927172333,\n",
       "  -0.03840756416320801,\n",
       "  -0.0031103105284273624,\n",
       "  0.03489653766155243,\n",
       "  -0.009601891040802002,\n",
       "  0.06374800950288773,\n",
       "  0.029599469155073166,\n",
       "  0.09122559428215027,\n",
       "  -0.10142283886671066,\n",
       "  -0.02421080879867077,\n",
       "  0.046742431819438934,\n",
       "  0.005743579473346472,\n",
       "  0.02724860981106758,\n",
       "  -0.019982313737273216,\n",
       "  0.011662710458040237,\n",
       "  -0.042712386697530746,\n",
       "  0.04546014592051506,\n",
       "  -0.0022459113970398903,\n",
       "  0.014685245230793953,\n",
       "  -0.05455828085541725,\n",
       "  -0.007789133582264185,\n",
       "  -0.016303369775414467,\n",
       "  0.007953235879540443,\n",
       "  0.031416043639183044,\n",
       "  0.06869397312402725,\n",
       "  0.04265132546424866,\n",
       "  0.08859995752573013,\n",
       "  -0.02335595153272152,\n",
       "  -0.1447153091430664,\n",
       "  0.09659899026155472,\n",
       "  0.009311850182712078,\n",
       "  0.03681996837258339,\n",
       "  -0.04552120715379715,\n",
       "  -0.1142457127571106,\n",
       "  0.023707052692770958,\n",
       "  -0.0735178142786026,\n",
       "  -0.0056825182400643826,\n",
       "  0.03630094975233078,\n",
       "  0.04533802345395088,\n",
       "  0.06231306865811348,\n",
       "  -0.01633390039205551,\n",
       "  -0.007953235879540443,\n",
       "  0.07498329132795334,\n",
       "  0.02607318013906479,\n",
       "  -0.041704874485731125,\n",
       "  0.034469109028577805,\n",
       "  0.0684497281908989,\n",
       "  0.0087622981518507,\n",
       "  0.02092876471579075,\n",
       "  0.028744611889123917,\n",
       "  0.030561186373233795,\n",
       "  -0.04234601929783821,\n",
       "  -0.038193847984075546,\n",
       "  0.028881998732686043,\n",
       "  0.001000832999125123,\n",
       "  -0.08359293639659882,\n",
       "  0.003173280041664839,\n",
       "  -0.021921010687947273,\n",
       "  0.06344269961118698,\n",
       "  0.0452464297413826,\n",
       "  -0.11241386830806732,\n",
       "  0.05959583818912506,\n",
       "  0.025035137310624123,\n",
       "  -0.058893632143735886,\n",
       "  -0.0548635870218277,\n",
       "  0.30726051330566406,\n",
       "  -0.01837945356965065,\n",
       "  0.035598743706941605,\n",
       "  0.058557797223329544,\n",
       "  -0.03935401514172554,\n",
       "  0.03419433534145355,\n",
       "  -0.050925131887197495,\n",
       "  -0.019142720848321915,\n",
       "  -0.0373084619641304,\n",
       "  -0.045826513320207596,\n",
       "  0.05721444636583328,\n",
       "  -0.007689908612519503,\n",
       "  -0.04100266844034195,\n",
       "  0.06032857298851013,\n",
       "  0.007613582070916891,\n",
       "  -0.003907924052327871,\n",
       "  -0.04026993364095688,\n",
       "  0.05254325643181801,\n",
       "  0.050864070653915405,\n",
       "  0.05263485014438629,\n",
       "  0.05043664202094078,\n",
       "  0.01057123951613903,\n",
       "  0.017494065687060356,\n",
       "  -0.0074952756986021996,\n",
       "  0.016837656497955322,\n",
       "  -0.0015732827596366405,\n",
       "  -0.025233587250113487,\n",
       "  0.0023985644802451134,\n",
       "  0.03608723357319832,\n",
       "  -0.031126001849770546,\n",
       "  0.021295132115483284,\n",
       "  0.009075237438082695,\n",
       "  0.010975770652294159,\n",
       "  -0.08853890001773834,\n",
       "  0.05568791553378105,\n",
       "  0.036270417273044586,\n",
       "  -0.02494354546070099,\n",
       "  0.003381269983947277,\n",
       "  -0.015326389111578465,\n",
       "  0.020898234099149704,\n",
       "  0.006690029986202717,\n",
       "  -0.07809741795063019,\n",
       "  -0.027889752760529518,\n",
       "  0.0882335901260376,\n",
       "  -0.07791423052549362,\n",
       "  0.012021445669233799,\n",
       "  0.034682825207710266,\n",
       "  -0.0001400116743752733,\n",
       "  0.05141362175345421,\n",
       "  -0.000184138014446944,\n",
       "  0.04054471105337143,\n",
       "  -0.03217931091785431,\n",
       "  0.08389823883771896,\n",
       "  0.0333700068295002,\n",
       "  0.016608675941824913,\n",
       "  0.01950908824801445,\n",
       "  0.01312054879963398,\n",
       "  -0.01883741468191147,\n",
       "  -0.038987647742033005,\n",
       "  -0.01917325146496296,\n",
       "  0.08188321441411972,\n",
       "  -0.007968501187860966,\n",
       "  0.007609765976667404,\n",
       "  -0.06258784234523773,\n",
       "  -0.019753333181142807,\n",
       "  -0.011105525307357311,\n",
       "  -0.17097166180610657,\n",
       "  0.007548704277724028,\n",
       "  0.051199909299612045,\n",
       "  -0.04716986045241356,\n",
       "  -0.0004651154449675232,\n",
       "  -0.010166708379983902,\n",
       "  -0.006445784587413073,\n",
       "  0.024042891338467598,\n",
       "  -0.03069857321679592,\n",
       "  0.06716743856668472,\n",
       "  -0.029492612928152084,\n",
       "  0.02657693438231945,\n",
       "  0.09421759843826294,\n",
       "  -0.006503029726445675,\n",
       "  -0.0057397629134356976,\n",
       "  -0.023004848510026932,\n",
       "  -0.029202571138739586,\n",
       "  -0.10093434900045395,\n",
       "  0.0508946031332016,\n",
       "  0.06124449521303177,\n",
       "  -0.02724860981106758,\n",
       "  0.016486553475260735,\n",
       "  -0.012960262596607208,\n",
       "  0.08347081393003464,\n",
       "  -0.015906471759080887,\n",
       "  0.025019871070981026,\n",
       "  0.030973348766565323,\n",
       "  -0.07321251183748245,\n",
       "  0.058832570910453796,\n",
       "  -0.03923189267516136,\n",
       "  -0.015799613669514656,\n",
       "  0.011303975246846676,\n",
       "  0.038926586508750916,\n",
       "  0.002831718185916543,\n",
       "  -0.05529101565480232,\n",
       "  0.014563122764229774,\n",
       "  -0.0067129279486835,\n",
       "  0.023936033248901367,\n",
       "  0.03398061916232109,\n",
       "  0.07205234467983246,\n",
       "  -0.004488006234169006,\n",
       "  0.0009807973401620984,\n",
       "  -0.049795497208833694,\n",
       "  0.03098861500620842,\n",
       "  0.01899006776511669,\n",
       "  -0.0006168146501295269,\n",
       "  0.01362430490553379,\n",
       "  0.1255420595407486,\n",
       "  -0.016440758481621742,\n",
       "  -0.0013261752901598811,\n",
       "  -0.07944076508283615,\n",
       "  -0.026668526232242584,\n",
       "  0.04054471105337143,\n",
       "  -0.0446663498878479,\n",
       "  -0.037735890597105026,\n",
       "  -0.004690271802246571,\n",
       "  0.05614587292075157,\n",
       "  0.025874730199575424,\n",
       "  -0.25816720724105835,\n",
       "  0.04231548681855202,\n",
       "  -0.008647807873785496,\n",
       "  -0.06722850352525711,\n",
       "  -0.00847988948225975,\n",
       "  -0.03437751904129982,\n",
       "  -0.0021581356413662434,\n",
       "  -0.04216283559799194,\n",
       "  0.06209935247898102,\n",
       "  0.040117282420396805,\n",
       "  -0.017723044380545616,\n",
       "  0.01382275391370058,\n",
       "  0.06380906701087952,\n",
       "  0.029843715950846672,\n",
       "  0.05648171156644821,\n",
       "  0.006758723873645067,\n",
       "  0.013983040116727352,\n",
       "  -0.06301527470350266,\n",
       "  0.03529343754053116,\n",
       "  0.009098134934902191,\n",
       "  -0.03697262331843376,\n",
       "  0.010250667110085487,\n",
       "  0.027462324127554893,\n",
       "  -0.014227285049855709,\n",
       "  -0.010258300229907036,\n",
       "  -0.09653793275356293,\n",
       "  0.05037558078765869,\n",
       "  0.005930579733103514,\n",
       "  0.012517568655312061,\n",
       "  0.013929611071944237,\n",
       "  0.040911078453063965,\n",
       "  0.053581301122903824,\n",
       "  -0.033339474350214005,\n",
       "  -0.12138988077640533,\n",
       "  -0.0020264722406864166,\n",
       "  0.03428592532873154,\n",
       "  0.03379743546247482,\n",
       "  0.06362588703632355,\n",
       "  -0.07638769596815109,\n",
       "  -0.09171408414840698,\n",
       "  0.001887176069431007,\n",
       "  0.025141993537545204,\n",
       "  0.04265132546424866,\n",
       "  -0.06490816920995712,\n",
       "  0.022027866914868355,\n",
       "  0.020028110593557358,\n",
       "  -0.016776595264673233,\n",
       "  0.038590747863054276,\n",
       "  -0.04527696222066879,\n",
       "  -0.027065426111221313,\n",
       "  0.04451369494199753,\n",
       "  -0.009479768574237823,\n",
       "  0.06722850352525711,\n",
       "  0.0220583975315094,\n",
       "  0.04759729281067848,\n",
       "  -0.0214935801923275,\n",
       "  -0.0548635870218277,\n",
       "  0.015738552436232567,\n",
       "  0.013715896755456924,\n",
       "  -0.0046635577455163,\n",
       "  -0.044361039996147156,\n",
       "  0.011540587991476059,\n",
       "  -0.06545772403478622,\n",
       "  -0.08115047961473465,\n",
       "  0.015860674902796745,\n",
       "  0.0015980890020728111,\n",
       "  -0.026317425072193146,\n",
       "  -0.1306712031364441,\n",
       "  -0.05648171156644821,\n",
       "  -0.12096245586872101,\n",
       "  -0.0008892053156159818,\n",
       "  0.002738218056038022,\n",
       "  -0.02973685786128044,\n",
       "  0.01599806360900402,\n",
       "  0.0226232148706913,\n",
       "  -0.02080664224922657,\n",
       "  0.0882335901260376,\n",
       "  0.029981102794408798,\n",
       "  0.03700315207242966,\n",
       "  -0.03623988851904869,\n",
       "  -0.006724376697093248,\n",
       "  0.11400146782398224,\n",
       "  0.03968985006213188,\n",
       "  -0.020821906626224518,\n",
       "  0.0007651745690964162,\n",
       "  0.04081948474049568,\n",
       "  0.0554131381213665,\n",
       "  -0.03086649253964424,\n",
       "  0.016929248347878456,\n",
       "  -0.03404168039560318,\n",
       "  -0.0023279625456780195,\n",
       "  -0.04146062955260277,\n",
       "  0.018700025975704193,\n",
       "  -0.08511946350336075,\n",
       "  0.06496923416852951,\n",
       "  -0.0087622981518507,\n",
       "  -0.15814879536628723,\n",
       "  -0.0008768022526055574,\n",
       "  0.021111948415637016,\n",
       "  0.013784591108560562,\n",
       "  -0.05874098092317581,\n",
       "  -0.024042891338467598,\n",
       "  0.026851711794734,\n",
       "  -0.017723044380545616,\n",
       "  -0.030011633411049843,\n",
       "  0.038590747863054276,\n",
       "  -0.04347565397620201,\n",
       "  -0.03636201098561287,\n",
       "  0.005171129480004311,\n",
       "  -0.021982071921229362,\n",
       "  -0.010388055816292763,\n",
       "  0.02414974756538868,\n",
       "  0.08206640183925629,\n",
       "  0.00922025740146637,\n",
       "  0.01410516258329153,\n",
       "  0.010380422696471214,\n",
       "  -0.024470319971442223,\n",
       "  -0.029492612928152084,\n",
       "  0.059626370668411255,\n",
       "  -0.07131960988044739,\n",
       "  -0.03069857321679592,\n",
       "  0.028851468116044998,\n",
       "  0.02567628026008606,\n",
       "  0.023279624059796333,\n",
       "  -0.0063923560082912445,\n",
       "  0.033553190529346466,\n",
       "  0.02160043828189373,\n",
       "  0.007186152972280979,\n",
       "  0.05434456467628479,\n",
       "  0.027569182217121124,\n",
       "  -0.023142237216234207,\n",
       "  -0.010357524268329144,\n",
       "  -0.04970390722155571,\n",
       "  -0.032209839671850204,\n",
       "  -0.030057430267333984,\n",
       "  0.02781342715024948,\n",
       "  -0.053398117423057556,\n",
       "  0.003934638109058142,\n",
       "  -0.1311596930027008,\n",
       "  0.019371701404452324,\n",
       "  0.0633205771446228,\n",
       "  -0.05077248066663742,\n",
       "  -0.04646765813231468,\n",
       "  0.03343106806278229,\n",
       "  -0.033400535583496094,\n",
       "  -0.010502545163035393,\n",
       "  -0.00972401350736618,\n",
       "  -0.039384543895721436,\n",
       "  0.0003277274954598397,\n",
       "  0.030347470194101334,\n",
       "  0.053398117423057556,\n",
       "  -0.00101419014390558,\n",
       "  -0.012906834483146667,\n",
       "  -0.04420838877558708,\n",
       "  0.033675312995910645,\n",
       "  0.04054471105337143,\n",
       "  0.026332689449191093,\n",
       "  0.006018355488777161,\n",
       "  -0.05605428293347359,\n",
       "  0.0163949616253376,\n",
       "  -0.013593774288892746]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b6797c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_embeddings = user_prompt_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f5c89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929b2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_embeddings = [get_embedding(embedding_client,model_name,x)[0] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c1c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similaraty_scores = cosine_similarity([user_prompt_embeddings], data_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee652d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73779758, 0.52622817]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_similaraty_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e06a7cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_entry_index=data_similaraty_scores.argmax()\n",
    "closest_entry_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5247a12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe iPhone 16 introduces several exciting updates, making it one of Apple\\'s most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\\n\\nPowered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Apple‚Äôs \"Camera Control\" button for more flexible photography options.\\n\\nApple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \\n9TO5MAC\\n\\nAPPLEMAGAZINE\\n.\\n\\nAdditionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[closest_entry_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47352cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e1943cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_with_data = f\"\"\"\n",
    "{data[closest_entry_index]}\n",
    "\n",
    "{user_prompt}\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d7473c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe iPhone 16 introduces several exciting updates, making it one of Apple\\'s most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\\n\\nPowered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Apple‚Äôs \"Camera Control\" button for more flexible photography options.\\n\\nApple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \\n9TO5MAC\\n\\nAPPLEMAGAZINE\\n.\\n\\nAdditionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\\n\\n\\nWhat\\'s new in iphone 16?\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt_with_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecec6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "969633a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, the new features and updates in the iPhone 16 include:\n",
      "\n",
      "1. Larger display sizes:\n",
      "   - Base model: 6.1-inch\n",
      "   - iPhone 16 Plus: 6.7-inch\n",
      "   - iPhone 16 Pro: 6.3-inch\n",
      "   - iPhone 16 Pro Max: 6.9-inch\n",
      "\n",
      "2. Thinner bezels and a more durable Ceramic Shield.\n",
      "\n",
      "3. New A18 chip (A18 Pro for Pro models) for improved performance, with:\n",
      "   - Enhanced neural engine capabilities\n",
      "   - Faster GPU for gaming\n",
      "   - Machine learning tasks\n",
      "\n",
      "4. Upgraded camera systems:\n",
      "   - Base iPhone 16: Dual-camera setup with a 48MP main sensor\n",
      "   - Pro models: 48MP Ultra Wide and 5x telephoto camera, with Apple's \"Camera Control\" button\n",
      "\n",
      "5. Advanced audio features:\n",
      "   - \"Audio Mix\" for refined audio capture during video recording\n",
      "\n",
      "6. Extended battery life, especially in the iPhone 16 Pro Max.\n",
      "\n",
      "7. Switch to USB-C for faster charging and data transfer.\n",
      "\n",
      "8. Support for up to 2x faster video encoding in Pro models.\n",
      "\n",
      "9. Starting prices remain consistent with previous generations:\n",
      "   - iPhone 16: $799\n",
      "   - Pro models: $999\n"
     ]
    }
   ],
   "source": [
    "messages = [{'role':'user','content':user_prompt_with_data}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67627e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00890ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b598fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e59445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
